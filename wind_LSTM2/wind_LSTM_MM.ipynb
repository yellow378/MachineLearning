{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindDataSet(Dataset):\n",
    "    def __init__(self,path,num_steps=50):\n",
    "        self.data = []\n",
    "        file = pd.read_csv(path,skiprows=1)\n",
    "        self.feature = np.array(file[[ \"Month\", \"Day\", \"Hour\", \"Minute\", \"surface air pressure (Pa)\", \"relative humidity at 2m (%)\", \"surface precipitation rate (mm/h)\", \"air temperature at 10m (C)\", \"wind direction at 10m (deg)\",\"wind speed at 10m (m/s)\"]])\n",
    "        self.target = np.array(file[\"wind speed at 10m (m/s)\"])\n",
    "        wind_len = len(self.feature)\n",
    "        for i in range(wind_len-num_steps-1):\n",
    "            self.data.append((self.feature[i:i+num_steps],self.target[i+num_steps:i+num_steps+10]))\n",
    "        self.data = self.data[:int(len(self.data)/250)*250]\n",
    "    def __len__(self):\n",
    "        return len(self.data)   \n",
    "    def __getitem__(self,index):\n",
    "        seq,pre = self.data[index]\n",
    "        return seq,pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=10\n",
    "HIDDEN_SIZE=50\n",
    "BATCH_SIZE=250\n",
    "OUTPUT_SIZE=10\n",
    "NUM_LAYERS=2\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstm,self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=INPUT_SIZE,hidden_size=HIDDEN_SIZE,num_layers=NUM_LAYERS)\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE,OUTPUT_SIZE)\n",
    "    def forward(self,x,state):\n",
    "        x = torch.transpose(x,dim0=0,dim1=1).reshape((x.shape[1],-1,INPUT_SIZE))\n",
    "        out,state = self.rnn(x,state)\n",
    "        out = self.fc(out)\n",
    "        return out[-1],state\n",
    "    def begin_state(self,batch_size,device):\n",
    "        return (torch.zeros((2,batch_size,HIDDEN_SIZE),device=device),torch.zeros((2,batch_size, HIDDEN_SIZE), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "net = lstm()\n",
    "lr = 0.001\n",
    "device = try_gpu()\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "epochs = 10\n",
    "num_steps=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(epoch,net,train_loader,device,train_loss):\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "    runing_loss=0\n",
    "    for batch_idx,(X,y) in enumerate(train_loader):\n",
    "        state=net.begin_state(batch_size=BATCH_SIZE, device=device)\n",
    "        for s in state:\n",
    "            s.detach_()\n",
    "        optimizer.zero_grad()\n",
    "        X,y = X.to(torch.float32).to(device),y.to(torch.float32).to(device)\n",
    "        y_hat,state = net(X,state)\n",
    "        #print(y_hat.shape,y.shape)\n",
    "        l = loss(y_hat,y).mean()\n",
    "        l.backward()\n",
    "        grad_clipping(net, 1)\n",
    "        optimizer.step()\n",
    "        runing_loss += l.item()\n",
    "        if batch_idx%400 == 399:\n",
    "            print(f'epoch:{epoch+1},batch_idx:{batch_idx+1},running_loss:{runing_loss/400}')\n",
    "            train_loss.append(l.item())\n",
    "            runing_loss=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_net(path = 'wind_10input.pt', net=None):\n",
    "    torch.save(net.state_dict(),path)\n",
    "# save_net(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(120):\n",
    "            dataset = WindDataSet(f'./datasets/{i}.csv',num_steps)\n",
    "            train_loader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)\n",
    "            train_epoch(epoch,net,train_loader,device,train_loss)\n",
    "        print(f'###epoch:{epoch+1},train_loss:{train_loss[-1]}')\n",
    "        save_net(path=f\"MM-epoch{epoch}.pt\",net=net.to('cpu'))\n",
    "        #net = net.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,batch_idx:400,running_loss:5.934961936920882\n",
      "epoch:1,batch_idx:400,running_loss:7.028252300769091\n",
      "epoch:1,batch_idx:400,running_loss:5.918150629848242\n",
      "epoch:1,batch_idx:400,running_loss:7.172445548325777\n",
      "epoch:1,batch_idx:400,running_loss:9.112944650053977\n",
      "epoch:1,batch_idx:400,running_loss:10.413066191971302\n",
      "epoch:1,batch_idx:400,running_loss:10.991364172995091\n",
      "epoch:1,batch_idx:400,running_loss:11.313820707648993\n",
      "epoch:1,batch_idx:400,running_loss:11.716999898403882\n",
      "epoch:1,batch_idx:400,running_loss:12.284496067687869\n",
      "epoch:1,batch_idx:400,running_loss:12.820943886637687\n",
      "epoch:1,batch_idx:400,running_loss:13.345446190237999\n",
      "epoch:1,batch_idx:400,running_loss:9.602950816601515\n",
      "epoch:1,batch_idx:400,running_loss:10.022972505539656\n",
      "epoch:1,batch_idx:400,running_loss:10.234902490675449\n",
      "epoch:1,batch_idx:400,running_loss:10.521180244982242\n",
      "epoch:1,batch_idx:400,running_loss:10.880924265086652\n",
      "epoch:1,batch_idx:400,running_loss:11.113455261588097\n",
      "epoch:1,batch_idx:400,running_loss:11.392467964738607\n",
      "epoch:1,batch_idx:400,running_loss:11.699997955709696\n",
      "epoch:1,batch_idx:400,running_loss:11.661887190639973\n",
      "epoch:1,batch_idx:400,running_loss:11.917902788370847\n",
      "epoch:1,batch_idx:400,running_loss:12.200831740573049\n",
      "epoch:1,batch_idx:400,running_loss:12.30455641977489\n",
      "epoch:1,batch_idx:400,running_loss:10.879165366292\n",
      "epoch:1,batch_idx:400,running_loss:11.051855370551348\n",
      "epoch:1,batch_idx:400,running_loss:11.406285140663385\n",
      "epoch:1,batch_idx:400,running_loss:11.753092807084322\n",
      "epoch:1,batch_idx:400,running_loss:11.765007229596376\n",
      "epoch:1,batch_idx:400,running_loss:11.506260467469692\n",
      "epoch:1,batch_idx:400,running_loss:11.932340634912252\n",
      "epoch:1,batch_idx:400,running_loss:12.320316832661629\n",
      "epoch:1,batch_idx:400,running_loss:11.702722811549902\n",
      "epoch:1,batch_idx:400,running_loss:11.545089330375195\n",
      "epoch:1,batch_idx:400,running_loss:12.023929806500673\n",
      "epoch:1,batch_idx:400,running_loss:11.960227107927203\n",
      "epoch:1,batch_idx:400,running_loss:12.822184002101421\n",
      "epoch:1,batch_idx:400,running_loss:12.652691198289395\n",
      "epoch:1,batch_idx:400,running_loss:12.33232240051031\n",
      "epoch:1,batch_idx:400,running_loss:12.354185979366303\n",
      "epoch:1,batch_idx:400,running_loss:12.230498988330364\n",
      "epoch:1,batch_idx:400,running_loss:12.036507437229156\n",
      "epoch:1,batch_idx:400,running_loss:12.554776685237885\n",
      "epoch:1,batch_idx:400,running_loss:12.955952969491483\n",
      "epoch:1,batch_idx:400,running_loss:12.072003971189261\n",
      "epoch:1,batch_idx:400,running_loss:11.627717838287353\n",
      "epoch:1,batch_idx:400,running_loss:12.176477210223675\n",
      "epoch:1,batch_idx:400,running_loss:12.16544252216816\n",
      "epoch:1,batch_idx:400,running_loss:13.558426252305507\n",
      "epoch:1,batch_idx:400,running_loss:13.36436697781086\n",
      "epoch:1,batch_idx:400,running_loss:13.137987646758557\n",
      "epoch:1,batch_idx:400,running_loss:13.136877913326025\n",
      "epoch:1,batch_idx:400,running_loss:12.813254268318415\n",
      "epoch:1,batch_idx:400,running_loss:12.44569044739008\n",
      "epoch:1,batch_idx:400,running_loss:12.675264725089074\n",
      "epoch:1,batch_idx:400,running_loss:12.824785278290511\n",
      "epoch:1,batch_idx:400,running_loss:12.464351970106364\n",
      "epoch:1,batch_idx:400,running_loss:12.014559074938298\n",
      "epoch:1,batch_idx:400,running_loss:12.21511182025075\n",
      "epoch:1,batch_idx:400,running_loss:12.168149614036084\n",
      "epoch:1,batch_idx:400,running_loss:13.777303780317306\n",
      "epoch:1,batch_idx:400,running_loss:13.54264350026846\n",
      "epoch:1,batch_idx:400,running_loss:13.31806657359004\n",
      "epoch:1,batch_idx:400,running_loss:13.65311614319682\n",
      "epoch:1,batch_idx:400,running_loss:13.677910611778497\n",
      "epoch:1,batch_idx:400,running_loss:13.210763514190912\n",
      "epoch:1,batch_idx:400,running_loss:12.760062081813812\n",
      "epoch:1,batch_idx:400,running_loss:12.716290559321642\n",
      "epoch:1,batch_idx:400,running_loss:12.625449128001929\n",
      "epoch:1,batch_idx:400,running_loss:12.353057675957679\n",
      "epoch:1,batch_idx:400,running_loss:12.076900488138198\n",
      "epoch:1,batch_idx:400,running_loss:12.001765644848346\n",
      "epoch:1,batch_idx:400,running_loss:13.894354295432567\n",
      "epoch:1,batch_idx:400,running_loss:14.00980614721775\n",
      "epoch:1,batch_idx:400,running_loss:13.520840790569782\n",
      "epoch:1,batch_idx:400,running_loss:13.600923689305782\n",
      "epoch:1,batch_idx:400,running_loss:13.970864146649838\n",
      "epoch:1,batch_idx:400,running_loss:13.812575879395007\n",
      "epoch:1,batch_idx:400,running_loss:13.412876708954572\n",
      "epoch:1,batch_idx:400,running_loss:13.120688201636076\n",
      "epoch:1,batch_idx:400,running_loss:12.79429835319519\n",
      "epoch:1,batch_idx:400,running_loss:12.485841916799545\n",
      "epoch:1,batch_idx:400,running_loss:12.22495440095663\n",
      "epoch:1,batch_idx:400,running_loss:12.074110275059939\n",
      "epoch:1,batch_idx:400,running_loss:13.591238496154547\n",
      "epoch:1,batch_idx:400,running_loss:14.385456551909447\n",
      "epoch:1,batch_idx:400,running_loss:14.143155675381422\n",
      "epoch:1,batch_idx:400,running_loss:13.844551436007023\n",
      "epoch:1,batch_idx:400,running_loss:14.198596297800542\n",
      "epoch:1,batch_idx:400,running_loss:14.32224295437336\n",
      "epoch:1,batch_idx:400,running_loss:13.862335886359215\n",
      "epoch:1,batch_idx:400,running_loss:13.41283015012741\n",
      "epoch:1,batch_idx:400,running_loss:13.131475775241851\n",
      "epoch:1,batch_idx:400,running_loss:12.68750638306141\n",
      "epoch:1,batch_idx:400,running_loss:12.245241297781467\n",
      "epoch:1,batch_idx:400,running_loss:12.026891147196293\n",
      "epoch:1,batch_idx:400,running_loss:13.563324444890021\n",
      "epoch:1,batch_idx:400,running_loss:13.998504133075476\n",
      "epoch:1,batch_idx:400,running_loss:14.394179524481297\n",
      "epoch:1,batch_idx:400,running_loss:14.29178822234273\n",
      "epoch:1,batch_idx:400,running_loss:14.341852110922337\n",
      "epoch:1,batch_idx:400,running_loss:14.305231575667857\n",
      "epoch:1,batch_idx:400,running_loss:13.863155543208123\n",
      "epoch:1,batch_idx:400,running_loss:13.393814502954482\n",
      "epoch:1,batch_idx:400,running_loss:13.263785249590875\n",
      "epoch:1,batch_idx:400,running_loss:12.894205713570118\n",
      "epoch:1,batch_idx:400,running_loss:12.441768272221088\n",
      "epoch:1,batch_idx:400,running_loss:12.051361644864082\n",
      "epoch:1,batch_idx:400,running_loss:13.703201861083507\n",
      "epoch:1,batch_idx:400,running_loss:13.69377535045147\n",
      "epoch:1,batch_idx:400,running_loss:14.277204957306385\n",
      "epoch:1,batch_idx:400,running_loss:14.335588594079018\n",
      "epoch:1,batch_idx:400,running_loss:14.145145234763623\n",
      "epoch:1,batch_idx:400,running_loss:13.983138948082924\n",
      "epoch:1,batch_idx:400,running_loss:13.690097099244595\n",
      "epoch:1,batch_idx:400,running_loss:13.330873682498932\n",
      "epoch:1,batch_idx:400,running_loss:13.081713280379772\n",
      "epoch:1,batch_idx:400,running_loss:12.800037680864333\n",
      "epoch:1,batch_idx:400,running_loss:12.428348366618156\n",
      "epoch:1,batch_idx:400,running_loss:12.051177326738834\n",
      "###epoch:1,train_loss:6.725133419036865\n",
      "epoch:2,batch_idx:400,running_loss:5.83384700588882\n",
      "epoch:2,batch_idx:400,running_loss:7.041436829566956\n",
      "epoch:2,batch_idx:400,running_loss:5.9258396980166435\n",
      "epoch:2,batch_idx:400,running_loss:7.179049288630486\n",
      "epoch:2,batch_idx:400,running_loss:9.121867030858994\n",
      "epoch:2,batch_idx:400,running_loss:10.419094841480256\n",
      "epoch:2,batch_idx:400,running_loss:10.997317798286677\n",
      "epoch:2,batch_idx:400,running_loss:11.319882553815841\n",
      "epoch:2,batch_idx:400,running_loss:11.719791713058948\n",
      "epoch:2,batch_idx:400,running_loss:12.286172809749841\n",
      "epoch:2,batch_idx:400,running_loss:12.822513237595558\n",
      "epoch:2,batch_idx:400,running_loss:13.347816816866398\n",
      "epoch:2,batch_idx:400,running_loss:9.603326812237501\n",
      "epoch:2,batch_idx:400,running_loss:10.023797311335802\n",
      "epoch:2,batch_idx:400,running_loss:10.23575514435768\n",
      "epoch:2,batch_idx:400,running_loss:10.521902780532837\n",
      "epoch:2,batch_idx:400,running_loss:10.881499678343534\n",
      "epoch:2,batch_idx:400,running_loss:11.11402211651206\n",
      "epoch:2,batch_idx:400,running_loss:11.392909574508668\n",
      "epoch:2,batch_idx:400,running_loss:11.700363632291555\n",
      "epoch:2,batch_idx:400,running_loss:11.662146612107755\n",
      "epoch:2,batch_idx:400,running_loss:11.918053598403931\n",
      "epoch:2,batch_idx:400,running_loss:12.200961340218782\n",
      "epoch:2,batch_idx:400,running_loss:12.30467765122652\n",
      "epoch:2,batch_idx:400,running_loss:10.879254737049342\n",
      "epoch:2,batch_idx:400,running_loss:11.0519907990098\n",
      "epoch:2,batch_idx:400,running_loss:11.406393992751838\n",
      "epoch:2,batch_idx:400,running_loss:11.753177317976952\n",
      "epoch:2,batch_idx:400,running_loss:11.765077037066222\n",
      "epoch:2,batch_idx:400,running_loss:11.506322781145572\n",
      "epoch:2,batch_idx:400,running_loss:11.932411086708306\n",
      "epoch:2,batch_idx:400,running_loss:12.320345212072134\n",
      "epoch:2,batch_idx:400,running_loss:11.702759314328432\n",
      "epoch:2,batch_idx:400,running_loss:11.545101508051157\n",
      "epoch:2,batch_idx:400,running_loss:12.023945118486882\n",
      "epoch:2,batch_idx:400,running_loss:11.960238710492849\n",
      "epoch:2,batch_idx:400,running_loss:12.82220248490572\n",
      "epoch:2,batch_idx:400,running_loss:12.652711207568645\n",
      "epoch:2,batch_idx:400,running_loss:12.332334296703339\n",
      "epoch:2,batch_idx:400,running_loss:12.354197352379561\n",
      "epoch:2,batch_idx:400,running_loss:12.230508706718684\n",
      "epoch:2,batch_idx:400,running_loss:12.036517401188611\n",
      "epoch:2,batch_idx:400,running_loss:12.554785636663437\n",
      "epoch:2,batch_idx:400,running_loss:12.955957381427288\n",
      "epoch:2,batch_idx:400,running_loss:12.072007735073566\n",
      "epoch:2,batch_idx:400,running_loss:11.627719587683679\n",
      "epoch:2,batch_idx:400,running_loss:12.176479796171188\n",
      "epoch:2,batch_idx:400,running_loss:12.165444202125073\n",
      "epoch:2,batch_idx:400,running_loss:13.558429147601128\n",
      "epoch:2,batch_idx:400,running_loss:13.36436894237995\n",
      "epoch:2,batch_idx:400,running_loss:13.13798872411251\n",
      "epoch:2,batch_idx:400,running_loss:13.136878715455532\n",
      "epoch:2,batch_idx:400,running_loss:12.813256024569274\n",
      "epoch:2,batch_idx:400,running_loss:12.445691161006689\n",
      "epoch:2,batch_idx:400,running_loss:12.675265436470509\n",
      "epoch:2,batch_idx:400,running_loss:12.824785824120045\n",
      "epoch:2,batch_idx:400,running_loss:12.464352643042803\n",
      "epoch:2,batch_idx:400,running_loss:12.014559248387814\n",
      "epoch:2,batch_idx:400,running_loss:12.215112283825874\n",
      "epoch:2,batch_idx:400,running_loss:12.16815004184842\n",
      "epoch:2,batch_idx:400,running_loss:13.777303567826747\n",
      "epoch:2,batch_idx:400,running_loss:13.542643609791995\n",
      "epoch:2,batch_idx:400,running_loss:13.318066622614861\n",
      "epoch:2,batch_idx:400,running_loss:13.653115951567889\n",
      "epoch:2,batch_idx:400,running_loss:13.677910379022359\n",
      "epoch:2,batch_idx:400,running_loss:13.210763369947673\n",
      "epoch:2,batch_idx:400,running_loss:12.760061528384686\n",
      "epoch:2,batch_idx:400,running_loss:12.716290490180254\n",
      "epoch:2,batch_idx:400,running_loss:12.625449287295341\n",
      "epoch:2,batch_idx:400,running_loss:12.353057664334774\n",
      "epoch:2,batch_idx:400,running_loss:12.076900724768638\n",
      "epoch:2,batch_idx:400,running_loss:12.00176575884223\n",
      "epoch:2,batch_idx:400,running_loss:13.894354321956634\n",
      "epoch:2,batch_idx:400,running_loss:14.009806327074767\n",
      "epoch:2,batch_idx:400,running_loss:13.520840396285058\n",
      "epoch:2,batch_idx:400,running_loss:13.600923333466053\n",
      "epoch:2,batch_idx:400,running_loss:13.970864105820656\n",
      "epoch:2,batch_idx:400,running_loss:13.812575974464416\n",
      "epoch:2,batch_idx:400,running_loss:13.412876651287078\n",
      "epoch:2,batch_idx:400,running_loss:13.120688364505767\n",
      "epoch:2,batch_idx:400,running_loss:12.794298374950886\n",
      "epoch:2,batch_idx:400,running_loss:12.485841836333275\n",
      "epoch:2,batch_idx:400,running_loss:12.224954413771629\n",
      "epoch:2,batch_idx:400,running_loss:12.074110133647919\n",
      "epoch:2,batch_idx:400,running_loss:13.591238456666469\n",
      "epoch:2,batch_idx:400,running_loss:14.385456951856613\n",
      "epoch:2,batch_idx:400,running_loss:14.143155955523252\n",
      "epoch:2,batch_idx:400,running_loss:13.844551736563444\n",
      "epoch:2,batch_idx:400,running_loss:14.198596531450749\n",
      "epoch:2,batch_idx:400,running_loss:14.322242838144302\n",
      "epoch:2,batch_idx:400,running_loss:13.862335884571076\n",
      "epoch:2,batch_idx:400,running_loss:13.412830232977868\n",
      "epoch:2,batch_idx:400,running_loss:13.131475743353366\n",
      "epoch:2,batch_idx:400,running_loss:12.687506281435489\n",
      "epoch:2,batch_idx:400,running_loss:12.245241232812404\n",
      "epoch:2,batch_idx:400,running_loss:12.026891330182552\n",
      "epoch:2,batch_idx:400,running_loss:13.563324682414532\n",
      "epoch:2,batch_idx:400,running_loss:13.998503946512937\n",
      "epoch:2,batch_idx:400,running_loss:14.394179048240185\n",
      "epoch:2,batch_idx:400,running_loss:14.291788259893655\n",
      "epoch:2,batch_idx:400,running_loss:14.341852025687695\n",
      "epoch:2,batch_idx:400,running_loss:14.305231619775295\n",
      "epoch:2,batch_idx:400,running_loss:13.863156134188175\n",
      "epoch:2,batch_idx:400,running_loss:13.393814599514007\n",
      "epoch:2,batch_idx:400,running_loss:13.26378511160612\n",
      "epoch:2,batch_idx:400,running_loss:12.894205748438836\n",
      "epoch:2,batch_idx:400,running_loss:12.441768418252469\n",
      "epoch:2,batch_idx:400,running_loss:12.051362004578113\n",
      "epoch:2,batch_idx:400,running_loss:13.703201791942119\n",
      "epoch:2,batch_idx:400,running_loss:13.693775057196618\n",
      "epoch:2,batch_idx:400,running_loss:14.27720508813858\n",
      "epoch:2,batch_idx:400,running_loss:14.335588454902172\n",
      "epoch:2,batch_idx:400,running_loss:14.145145283341408\n",
      "epoch:2,batch_idx:400,running_loss:13.983138984441757\n",
      "epoch:2,batch_idx:400,running_loss:13.690097106397152\n",
      "epoch:2,batch_idx:400,running_loss:13.330873498916626\n",
      "epoch:2,batch_idx:400,running_loss:13.081713527739048\n",
      "epoch:2,batch_idx:400,running_loss:12.800037613213062\n",
      "epoch:2,batch_idx:400,running_loss:12.428348337709904\n",
      "epoch:2,batch_idx:400,running_loss:12.051177407205104\n",
      "###epoch:2,train_loss:6.725133419036865\n",
      "epoch:3,batch_idx:400,running_loss:5.833847072497011\n",
      "epoch:3,batch_idx:400,running_loss:7.041436893939972\n",
      "epoch:3,batch_idx:400,running_loss:5.925839576423169\n",
      "epoch:3,batch_idx:400,running_loss:7.179049232006073\n",
      "epoch:3,batch_idx:400,running_loss:9.121866848915815\n",
      "epoch:3,batch_idx:400,running_loss:10.419094835072755\n",
      "epoch:3,batch_idx:400,running_loss:10.997317894548178\n",
      "epoch:3,batch_idx:400,running_loss:11.31988245666027\n",
      "epoch:3,batch_idx:400,running_loss:11.719791820645332\n",
      "epoch:3,batch_idx:400,running_loss:12.286172930374741\n",
      "epoch:3,batch_idx:400,running_loss:12.822513049542904\n",
      "epoch:3,batch_idx:400,running_loss:13.347816351950168\n",
      "epoch:3,batch_idx:400,running_loss:9.603326731175184\n",
      "epoch:3,batch_idx:400,running_loss:10.023797343820334\n",
      "epoch:3,batch_idx:400,running_loss:10.235754902362823\n",
      "epoch:3,batch_idx:400,running_loss:10.521902885735035\n",
      "epoch:3,batch_idx:400,running_loss:10.881499616205693\n",
      "epoch:3,batch_idx:400,running_loss:11.114022021442652\n",
      "epoch:3,batch_idx:400,running_loss:11.392909591794014\n",
      "epoch:3,batch_idx:400,running_loss:11.700363700389863\n",
      "epoch:3,batch_idx:400,running_loss:11.662146663367748\n",
      "epoch:3,batch_idx:400,running_loss:11.918053551092743\n",
      "epoch:3,batch_idx:400,running_loss:12.200961402729154\n",
      "epoch:3,batch_idx:400,running_loss:12.304677709490061\n",
      "epoch:3,batch_idx:400,running_loss:10.879254602640867\n",
      "epoch:3,batch_idx:400,running_loss:11.051990770995618\n",
      "epoch:3,batch_idx:400,running_loss:11.406393847316503\n",
      "epoch:3,batch_idx:400,running_loss:11.753177370876074\n",
      "epoch:3,batch_idx:400,running_loss:11.765077209025621\n",
      "epoch:3,batch_idx:400,running_loss:11.50632270231843\n",
      "epoch:3,batch_idx:400,running_loss:11.932411004453897\n",
      "epoch:3,batch_idx:400,running_loss:12.320345235317946\n",
      "epoch:3,batch_idx:400,running_loss:11.702759242206811\n",
      "epoch:3,batch_idx:400,running_loss:11.545101470649243\n",
      "epoch:3,batch_idx:400,running_loss:12.023945133537055\n",
      "epoch:3,batch_idx:400,running_loss:11.960238779336214\n",
      "epoch:3,batch_idx:400,running_loss:12.822202405035496\n",
      "epoch:3,batch_idx:400,running_loss:12.652710999846459\n",
      "epoch:3,batch_idx:400,running_loss:12.332334178686143\n",
      "epoch:3,batch_idx:400,running_loss:12.354197536557912\n",
      "epoch:3,batch_idx:400,running_loss:12.230508955270052\n",
      "epoch:3,batch_idx:400,running_loss:12.036517674922942\n",
      "epoch:3,batch_idx:400,running_loss:12.554785873889923\n",
      "epoch:3,batch_idx:400,running_loss:12.95595716804266\n",
      "epoch:3,batch_idx:400,running_loss:12.072007678300142\n",
      "epoch:3,batch_idx:400,running_loss:11.627719811201096\n",
      "epoch:3,batch_idx:400,running_loss:12.176479853838682\n",
      "epoch:3,batch_idx:400,running_loss:12.165443996489048\n",
      "epoch:3,batch_idx:400,running_loss:13.558428859710693\n",
      "epoch:3,batch_idx:400,running_loss:13.364368776977063\n",
      "epoch:3,batch_idx:400,running_loss:13.137988809645176\n",
      "epoch:3,batch_idx:400,running_loss:13.136878985613585\n",
      "epoch:3,batch_idx:400,running_loss:12.813255874365568\n",
      "epoch:3,batch_idx:400,running_loss:12.445691134482622\n",
      "epoch:3,batch_idx:400,running_loss:12.67526542276144\n",
      "epoch:3,batch_idx:400,running_loss:12.824785581380128\n",
      "epoch:3,batch_idx:400,running_loss:12.464352782815695\n",
      "epoch:3,batch_idx:400,running_loss:12.014559169113635\n",
      "epoch:3,batch_idx:400,running_loss:12.215112009048461\n",
      "epoch:3,batch_idx:400,running_loss:12.168149924278259\n",
      "epoch:3,batch_idx:400,running_loss:13.777303561270237\n",
      "epoch:3,batch_idx:400,running_loss:13.542643197327852\n",
      "epoch:3,batch_idx:400,running_loss:13.318066548407078\n",
      "epoch:3,batch_idx:400,running_loss:13.653116014897824\n",
      "epoch:3,batch_idx:400,running_loss:13.677910332530736\n",
      "epoch:3,batch_idx:400,running_loss:13.210763605833053\n",
      "epoch:3,batch_idx:400,running_loss:12.760061425864697\n",
      "epoch:3,batch_idx:400,running_loss:12.716290808022022\n",
      "epoch:3,batch_idx:400,running_loss:12.62544908285141\n",
      "epoch:3,batch_idx:400,running_loss:12.353057761490344\n",
      "epoch:3,batch_idx:400,running_loss:12.07690067768097\n",
      "epoch:3,batch_idx:400,running_loss:12.0017658790946\n",
      "epoch:3,batch_idx:400,running_loss:13.894353970885277\n",
      "epoch:3,batch_idx:400,running_loss:14.009806226342917\n",
      "epoch:3,batch_idx:400,running_loss:13.520840838178993\n",
      "epoch:3,batch_idx:400,running_loss:13.600923518836499\n",
      "epoch:3,batch_idx:400,running_loss:13.970863955914973\n",
      "epoch:3,batch_idx:400,running_loss:13.812576016634702\n",
      "epoch:3,batch_idx:400,running_loss:13.41287658572197\n",
      "epoch:3,batch_idx:400,running_loss:13.120688301175832\n",
      "epoch:3,batch_idx:400,running_loss:12.794298258423805\n",
      "epoch:3,batch_idx:400,running_loss:12.485841940939427\n",
      "epoch:3,batch_idx:400,running_loss:12.224954424500465\n",
      "epoch:3,batch_idx:400,running_loss:12.074110083431005\n",
      "epoch:3,batch_idx:400,running_loss:13.59123841777444\n",
      "epoch:3,batch_idx:400,running_loss:14.385456826090813\n",
      "epoch:3,batch_idx:400,running_loss:14.1431558342278\n",
      "epoch:3,batch_idx:400,running_loss:13.844551839232444\n",
      "epoch:3,batch_idx:400,running_loss:14.198596637547016\n",
      "epoch:3,batch_idx:400,running_loss:14.322242929041385\n",
      "epoch:3,batch_idx:400,running_loss:13.862335857748985\n",
      "epoch:3,batch_idx:400,running_loss:13.41283038765192\n",
      "epoch:3,batch_idx:400,running_loss:13.131475711464882\n",
      "epoch:3,batch_idx:400,running_loss:12.68750625938177\n",
      "epoch:3,batch_idx:400,running_loss:12.245241169929505\n",
      "epoch:3,batch_idx:400,running_loss:12.026891173422337\n",
      "epoch:3,batch_idx:400,running_loss:13.563324178159236\n",
      "epoch:3,batch_idx:400,running_loss:13.998503874242306\n",
      "epoch:3,batch_idx:400,running_loss:14.394179118573666\n",
      "epoch:3,batch_idx:400,running_loss:14.291788283884525\n",
      "epoch:3,batch_idx:400,running_loss:14.34185254752636\n",
      "epoch:3,batch_idx:400,running_loss:14.305231412053109\n",
      "epoch:3,batch_idx:400,running_loss:13.863155812621116\n",
      "epoch:3,batch_idx:400,running_loss:13.393814704418183\n",
      "epoch:3,batch_idx:400,running_loss:13.263785199522973\n",
      "epoch:3,batch_idx:400,running_loss:12.89420559644699\n",
      "epoch:3,batch_idx:400,running_loss:12.44176849067211\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m120\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mWindDataSet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset,batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m         train_epoch(epoch,net,train_loader,device,train_loss)\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mWindDataSet.__init__\u001b[0;34m(self, path, num_steps)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,path,num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(file[[ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinute\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurface air pressure (Pa)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative humidity at 2m (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurface precipitation rate (mm/h)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mair temperature at 10m (C)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind direction at 10m (deg)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind speed at 10m (m/s)\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind speed at 10m (m/s)\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(path='MM_epoch0.pt',net=None):\n",
    "    net.load_state_dict(torch.load(path))\n",
    "load_net(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix,net,device):\n",
    "    state = net.begin_state(batch_size=1,device=device)\n",
    "    outputs = [prefix[0]]\n",
    "    get_input = lambda:torch.tensor([outputs[-1]],device=device).reshape(1,1,INPUT_SIZE)\n",
    "    for y in prefix[1:]:\n",
    "        _,state = net(get_input(),state)\n",
    "        outputs.append(y)\n",
    "    y_hat,_ = net(get_input(),state)\n",
    "    return y_hat#torch.cat(outputs,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WindDataSet('.datasets/141.csv',num_steps=100)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "preds,truthes=[],[]\n",
    "for batch_idx,(X, y) in enumerate(test_loader):\n",
    "    if batch_idx % 10 == 0:\n",
    "        X = (X.reshape(1,1,INPUT_SIZE).to(torch.float32))\n",
    "        pred = np.array(predict(X,net.to(device),device).reshape(-1).to('cpu').detach())\n",
    "        truth=y.reshape(-1).detach().numpy()\n",
    "        preds= np.append(preds,pred)\n",
    "        truthes= np.append(truthes,truth)\n",
    "    if batch_idx > 100:\n",
    "        break\n",
    "    \n",
    "print(preds)\n",
    "print(truthes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(truth, label='True Values', color='blue')\n",
    "plt.plot(preds[100:], label='Predictions', color='red')\n",
    "plt.title('风速长期预测',fontproperties=my_font)\n",
    "plt.xlabel('样本',fontproperties=my_font)\n",
    "plt.ylabel('风速',fontproperties=my_font)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
