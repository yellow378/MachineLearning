{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindDataSet(Dataset):\n",
    "    def __init__(self,path,num_steps=50):\n",
    "        self.data = []\n",
    "        file = pd.read_csv(path,skiprows=1)\n",
    "        self.feature = np.array(file[[ \"Month\", \"Day\", \"Hour\", \"Minute\", \"surface air pressure (Pa)\", \"relative humidity at 2m (%)\", \"surface precipitation rate (mm/h)\", \"air temperature at 10m (C)\", \"wind direction at 10m (deg)\",\"wind speed at 10m (m/s)\"]])\n",
    "        self.target = np.array(file[\"wind speed at 10m (m/s)\"])\n",
    "        wind_len = len(self.feature)\n",
    "        for i in range(wind_len-num_steps-1):\n",
    "            self.data.append((self.feature[i:i+num_steps],self.target[i+num_steps:i+num_steps+10]))\n",
    "        self.data = self.data[:int(len(self.data)/250)*250]\n",
    "    def __len__(self):\n",
    "        return len(self.data)   \n",
    "    def __getitem__(self,index):\n",
    "        seq,pre = self.data[index]\n",
    "        return seq,pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=10\n",
    "HIDDEN_SIZE=512\n",
    "BATCH_SIZE=250\n",
    "OUTPUT_SIZE=10\n",
    "NUM_LAYERS=4\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstm,self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=INPUT_SIZE,hidden_size=HIDDEN_SIZE,num_layers=NUM_LAYERS)\n",
    "        self.fc1 = nn.Linear(HIDDEN_SIZE,100)\n",
    "        self.fc2 = nn.Linear(100,OUTPUT_SIZE)\n",
    "    def forward(self,x,state):\n",
    "        x = torch.transpose(x,dim0=0,dim1=1).reshape((x.shape[1],-1,INPUT_SIZE))\n",
    "        out,state = self.rnn(x,state)\n",
    "        out = self.fc1(out)\n",
    "        out = nn.functional.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out[-1],state\n",
    "    def begin_state(self,batch_size,device):\n",
    "        return (torch.zeros((4,batch_size,HIDDEN_SIZE),device=device),torch.zeros((4,batch_size, HIDDEN_SIZE), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "net = lstm()\n",
    "lr = 0.01\n",
    "device = try_gpu()\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "epochs = 100\n",
    "num_steps=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(epoch,net,train_loader,device,train_loss):\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "    runing_loss=0\n",
    "    for batch_idx,(X,y) in enumerate(train_loader):\n",
    "        state=net.begin_state(batch_size=BATCH_SIZE, device=device)\n",
    "        for s in state:\n",
    "            s.detach_()\n",
    "        optimizer.zero_grad()\n",
    "        X,y = X.to(torch.float32).to(device),y.to(torch.float32).to(device)\n",
    "        y_hat,state = net(X,state)\n",
    "        #print(y_hat.shape,y.shape)\n",
    "        l = loss(y_hat,y).mean()\n",
    "        l.backward()\n",
    "        grad_clipping(net, 1)\n",
    "        optimizer.step()\n",
    "        runing_loss = l.item()\n",
    "        if epoch%50 == 49 and batch_idx % 400 == 399:\n",
    "            print(f'file:{epoch+1},running_loss:{runing_loss}')\n",
    "            train_loss.append(l.item())\n",
    "            runing_loss=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_net(path = 'wind_10input.pt', net=None):\n",
    "    torch.save(net.state_dict(),path)\n",
    "# save_net(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(120):\n",
    "            dataset = WindDataSet(f'./datasets/{i}.csv',num_steps)\n",
    "            train_loader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)\n",
    "            train_epoch(i,net,train_loader,device,train_loss)\n",
    "        print(f'###epoch:{epoch+1},train_loss:{train_loss[-1]}')\n",
    "        save_net(path=f\"MM2-epoch{epoch}.pt\",net=net.to('cpu'))\n",
    "        #net = net.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:50,running_loss:3.864410877227783\n",
      "file:50,running_loss:25.14171028137207\n",
      "file:50,running_loss:35.517513275146484\n",
      "file:50,running_loss:10.230931282043457\n",
      "file:50,running_loss:3.9211156368255615\n",
      "file:50,running_loss:17.12759017944336\n",
      "file:50,running_loss:50.433349609375\n",
      "file:50,running_loss:19.919673919677734\n",
      "file:50,running_loss:10.888322830200195\n",
      "file:50,running_loss:17.699094772338867\n",
      "file:50,running_loss:34.02685546875\n",
      "file:50,running_loss:63.12394714355469\n",
      "file:50,running_loss:47.44464874267578\n",
      "file:50,running_loss:37.1748161315918\n",
      "file:50,running_loss:32.45948028564453\n",
      "file:50,running_loss:12.774920463562012\n",
      "file:50,running_loss:50.58994674682617\n",
      "file:50,running_loss:10.688152313232422\n",
      "file:50,running_loss:21.907915115356445\n",
      "file:50,running_loss:8.875203132629395\n",
      "file:50,running_loss:16.022724151611328\n",
      "file:50,running_loss:22.73672103881836\n",
      "file:50,running_loss:6.99951171875\n",
      "file:50,running_loss:32.01607894897461\n",
      "file:50,running_loss:4.28934907913208\n",
      "file:50,running_loss:9.446198463439941\n",
      "file:50,running_loss:28.43423080444336\n",
      "file:50,running_loss:30.240386962890625\n",
      "file:50,running_loss:36.9652214050293\n",
      "file:50,running_loss:20.5828914642334\n",
      "file:50,running_loss:12.729132652282715\n",
      "file:50,running_loss:27.91716194152832\n",
      "file:50,running_loss:84.20667266845703\n",
      "file:50,running_loss:40.93379211425781\n",
      "file:50,running_loss:6.129458427429199\n",
      "file:50,running_loss:3.672985792160034\n",
      "file:50,running_loss:8.442255973815918\n",
      "file:50,running_loss:7.3077592849731445\n",
      "file:50,running_loss:9.452759742736816\n",
      "file:50,running_loss:14.316105842590332\n",
      "file:50,running_loss:10.505362510681152\n",
      "file:50,running_loss:8.88255786895752\n",
      "file:50,running_loss:16.905136108398438\n",
      "file:50,running_loss:37.78316116333008\n",
      "file:50,running_loss:76.60822296142578\n",
      "file:50,running_loss:29.139631271362305\n",
      "file:50,running_loss:2.0243172645568848\n",
      "file:50,running_loss:30.556612014770508\n",
      "file:50,running_loss:60.3619499206543\n",
      "file:50,running_loss:57.115535736083984\n",
      "file:50,running_loss:16.117584228515625\n",
      "file:50,running_loss:41.840152740478516\n",
      "file:50,running_loss:18.995515823364258\n",
      "file:50,running_loss:26.101863861083984\n",
      "file:50,running_loss:50.398658752441406\n",
      "file:50,running_loss:42.8636589050293\n",
      "file:50,running_loss:33.45559310913086\n",
      "file:50,running_loss:14.921161651611328\n",
      "file:50,running_loss:49.86024856567383\n",
      "file:50,running_loss:39.717369079589844\n",
      "file:50,running_loss:1.5374088287353516\n",
      "file:50,running_loss:42.124656677246094\n",
      "file:50,running_loss:62.97821044921875\n",
      "file:50,running_loss:23.69046974182129\n",
      "file:50,running_loss:11.065892219543457\n",
      "file:50,running_loss:6.082205295562744\n",
      "file:50,running_loss:9.460163116455078\n",
      "file:50,running_loss:19.91941261291504\n",
      "file:50,running_loss:6.412547588348389\n",
      "file:50,running_loss:3.366023063659668\n",
      "file:50,running_loss:30.10177993774414\n",
      "file:50,running_loss:10.633346557617188\n",
      "file:50,running_loss:18.12213134765625\n",
      "file:50,running_loss:19.343225479125977\n",
      "file:50,running_loss:13.026061058044434\n",
      "file:50,running_loss:15.585693359375\n",
      "file:50,running_loss:6.505867958068848\n",
      "file:50,running_loss:18.014482498168945\n",
      "file:50,running_loss:21.180492401123047\n",
      "file:50,running_loss:11.23664379119873\n",
      "file:50,running_loss:9.052715301513672\n",
      "file:50,running_loss:4.75487756729126\n",
      "file:50,running_loss:22.55954933166504\n",
      "file:50,running_loss:11.14050579071045\n",
      "file:50,running_loss:8.053866386413574\n",
      "file:50,running_loss:18.156963348388672\n",
      "file:50,running_loss:47.62401580810547\n",
      "file:50,running_loss:17.515151977539062\n",
      "file:50,running_loss:15.759847640991211\n",
      "file:50,running_loss:33.32864761352539\n",
      "file:50,running_loss:18.721284866333008\n",
      "file:50,running_loss:16.00613784790039\n",
      "file:50,running_loss:11.298619270324707\n",
      "file:50,running_loss:30.513654708862305\n",
      "file:50,running_loss:12.091926574707031\n",
      "file:50,running_loss:9.298627853393555\n",
      "file:50,running_loss:7.759832382202148\n",
      "file:50,running_loss:15.281424522399902\n",
      "file:50,running_loss:24.12041473388672\n",
      "file:50,running_loss:11.096878051757812\n",
      "file:50,running_loss:37.599586486816406\n",
      "file:50,running_loss:7.444377899169922\n",
      "file:50,running_loss:8.581400871276855\n",
      "file:50,running_loss:10.114779472351074\n",
      "file:50,running_loss:8.176986694335938\n",
      "file:50,running_loss:8.665995597839355\n",
      "file:50,running_loss:13.233262062072754\n",
      "file:50,running_loss:5.233027935028076\n",
      "file:50,running_loss:12.9356107711792\n",
      "file:50,running_loss:4.938608646392822\n",
      "file:50,running_loss:2.477057933807373\n",
      "file:50,running_loss:3.802438259124756\n",
      "file:50,running_loss:11.979462623596191\n",
      "file:50,running_loss:21.916221618652344\n",
      "file:50,running_loss:21.049571990966797\n",
      "file:50,running_loss:21.53927993774414\n",
      "file:50,running_loss:15.4791259765625\n",
      "file:50,running_loss:10.350234985351562\n",
      "file:50,running_loss:6.565208435058594\n",
      "file:50,running_loss:9.00989055633545\n",
      "file:50,running_loss:25.848548889160156\n",
      "file:50,running_loss:10.89696216583252\n",
      "file:50,running_loss:9.330288887023926\n",
      "file:50,running_loss:18.159543991088867\n",
      "file:50,running_loss:5.979736804962158\n",
      "file:50,running_loss:8.180356979370117\n",
      "file:50,running_loss:12.33462905883789\n",
      "file:50,running_loss:6.308020114898682\n",
      "file:50,running_loss:15.800578117370605\n",
      "file:50,running_loss:27.834774017333984\n",
      "file:50,running_loss:25.077165603637695\n",
      "file:50,running_loss:8.929049491882324\n",
      "file:50,running_loss:9.30278491973877\n",
      "file:50,running_loss:10.723237991333008\n",
      "file:50,running_loss:6.495943546295166\n",
      "file:50,running_loss:5.100177764892578\n",
      "file:50,running_loss:7.057409763336182\n",
      "file:50,running_loss:5.903441429138184\n",
      "file:50,running_loss:4.758998870849609\n",
      "file:50,running_loss:4.978933334350586\n",
      "file:50,running_loss:8.0547456741333\n",
      "file:50,running_loss:6.851627349853516\n",
      "file:50,running_loss:18.87384605407715\n",
      "file:50,running_loss:8.520578384399414\n",
      "file:50,running_loss:8.937644958496094\n",
      "file:50,running_loss:10.56430721282959\n",
      "file:50,running_loss:7.558907508850098\n",
      "file:50,running_loss:22.40618324279785\n",
      "file:50,running_loss:8.196199417114258\n",
      "file:50,running_loss:4.7678937911987305\n",
      "file:50,running_loss:5.218732833862305\n",
      "file:50,running_loss:10.102774620056152\n",
      "file:50,running_loss:13.438338279724121\n",
      "file:50,running_loss:9.56019115447998\n",
      "file:50,running_loss:12.33562183380127\n",
      "file:50,running_loss:3.3051576614379883\n",
      "file:50,running_loss:8.549602508544922\n",
      "file:50,running_loss:17.18975257873535\n",
      "file:50,running_loss:21.510927200317383\n",
      "file:50,running_loss:22.59190559387207\n",
      "file:50,running_loss:13.748737335205078\n",
      "file:50,running_loss:13.226215362548828\n",
      "file:50,running_loss:19.320398330688477\n",
      "file:50,running_loss:10.00047779083252\n",
      "file:50,running_loss:11.990925788879395\n",
      "file:50,running_loss:14.95304012298584\n",
      "file:50,running_loss:14.645574569702148\n",
      "file:50,running_loss:15.4656400680542\n",
      "file:50,running_loss:4.6122236251831055\n",
      "file:50,running_loss:8.856354713439941\n",
      "file:50,running_loss:9.424431800842285\n",
      "file:50,running_loss:14.101749420166016\n",
      "file:50,running_loss:19.229930877685547\n",
      "file:50,running_loss:9.972838401794434\n",
      "file:50,running_loss:13.161813735961914\n",
      "file:50,running_loss:10.17200756072998\n",
      "file:50,running_loss:13.756449699401855\n",
      "file:50,running_loss:21.020944595336914\n",
      "file:50,running_loss:16.664043426513672\n",
      "file:50,running_loss:9.211292266845703\n",
      "file:50,running_loss:3.0811238288879395\n",
      "file:50,running_loss:7.2487263679504395\n",
      "file:50,running_loss:6.480786323547363\n",
      "file:50,running_loss:7.852010726928711\n",
      "file:50,running_loss:11.5632905960083\n",
      "file:50,running_loss:5.618898868560791\n",
      "file:50,running_loss:4.944391250610352\n",
      "file:50,running_loss:6.470787048339844\n",
      "file:50,running_loss:18.621891021728516\n",
      "file:50,running_loss:9.956645965576172\n",
      "file:50,running_loss:14.314509391784668\n",
      "file:50,running_loss:18.699365615844727\n",
      "file:50,running_loss:10.32176685333252\n",
      "file:50,running_loss:3.1738405227661133\n",
      "file:50,running_loss:12.580878257751465\n",
      "file:50,running_loss:9.878527641296387\n",
      "file:50,running_loss:8.97801685333252\n",
      "file:50,running_loss:15.933204650878906\n",
      "file:50,running_loss:14.173789024353027\n",
      "file:50,running_loss:13.200809478759766\n",
      "file:50,running_loss:17.252588272094727\n",
      "file:50,running_loss:15.944087028503418\n",
      "file:50,running_loss:10.752325057983398\n",
      "file:50,running_loss:5.165822505950928\n",
      "file:50,running_loss:5.964081764221191\n",
      "file:50,running_loss:28.390993118286133\n",
      "file:50,running_loss:20.524768829345703\n",
      "file:50,running_loss:6.34245491027832\n",
      "file:50,running_loss:18.077198028564453\n",
      "file:50,running_loss:12.439562797546387\n",
      "file:50,running_loss:21.93067169189453\n",
      "file:50,running_loss:8.77363395690918\n",
      "file:50,running_loss:10.396956443786621\n",
      "file:50,running_loss:9.587202072143555\n",
      "file:50,running_loss:8.473464965820312\n",
      "file:50,running_loss:5.509661674499512\n",
      "file:50,running_loss:3.664999008178711\n",
      "file:50,running_loss:16.14468002319336\n",
      "file:50,running_loss:3.8011507987976074\n",
      "file:50,running_loss:6.848923206329346\n",
      "file:50,running_loss:9.369708061218262\n",
      "file:50,running_loss:7.956234931945801\n",
      "file:50,running_loss:12.633421897888184\n",
      "file:50,running_loss:13.423025131225586\n",
      "file:50,running_loss:10.294429779052734\n",
      "file:50,running_loss:12.983506202697754\n",
      "file:50,running_loss:10.81114673614502\n",
      "file:50,running_loss:21.256973266601562\n",
      "file:50,running_loss:8.184601783752441\n",
      "file:50,running_loss:6.7918171882629395\n",
      "file:50,running_loss:2.4519855976104736\n",
      "file:50,running_loss:7.610693454742432\n",
      "file:50,running_loss:15.03192138671875\n",
      "file:50,running_loss:16.8016300201416\n",
      "file:50,running_loss:7.6839094161987305\n",
      "file:50,running_loss:9.656744003295898\n",
      "file:50,running_loss:8.812812805175781\n",
      "file:50,running_loss:9.531821250915527\n",
      "file:50,running_loss:0.3112305998802185\n",
      "file:50,running_loss:2.8082618713378906\n",
      "file:50,running_loss:10.166703224182129\n",
      "file:50,running_loss:5.164675235748291\n",
      "file:50,running_loss:4.89198637008667\n",
      "file:50,running_loss:4.776865482330322\n",
      "file:50,running_loss:8.820879936218262\n",
      "file:50,running_loss:16.403667449951172\n",
      "file:50,running_loss:21.0170955657959\n",
      "file:50,running_loss:11.389789581298828\n",
      "file:50,running_loss:12.027235984802246\n",
      "file:50,running_loss:4.23244571685791\n",
      "file:50,running_loss:9.7195405960083\n",
      "file:50,running_loss:17.577312469482422\n",
      "file:50,running_loss:10.711199760437012\n",
      "file:50,running_loss:3.4557647705078125\n",
      "file:50,running_loss:7.370924949645996\n",
      "file:50,running_loss:14.888460159301758\n",
      "file:50,running_loss:16.17524528503418\n",
      "file:50,running_loss:11.624266624450684\n",
      "file:50,running_loss:6.588724613189697\n",
      "file:50,running_loss:6.400701522827148\n",
      "file:50,running_loss:2.745640277862549\n",
      "file:50,running_loss:4.782556533813477\n",
      "file:50,running_loss:6.078962326049805\n",
      "file:50,running_loss:15.131733894348145\n",
      "file:50,running_loss:15.441088676452637\n",
      "file:50,running_loss:8.656217575073242\n",
      "file:50,running_loss:4.45405912399292\n",
      "file:50,running_loss:3.0105338096618652\n",
      "file:50,running_loss:15.11845588684082\n",
      "file:50,running_loss:9.275949478149414\n",
      "file:50,running_loss:9.011958122253418\n",
      "file:50,running_loss:16.36052703857422\n",
      "file:50,running_loss:7.692384243011475\n",
      "file:50,running_loss:13.687868118286133\n",
      "file:50,running_loss:4.470999717712402\n",
      "file:50,running_loss:1.1239840984344482\n",
      "file:50,running_loss:6.169999599456787\n",
      "file:50,running_loss:8.737167358398438\n",
      "file:50,running_loss:14.643865585327148\n",
      "file:50,running_loss:14.48237419128418\n",
      "file:50,running_loss:13.005866050720215\n",
      "file:50,running_loss:7.881530284881592\n",
      "file:50,running_loss:12.460267066955566\n",
      "file:50,running_loss:7.196407794952393\n",
      "file:50,running_loss:3.96171236038208\n",
      "file:50,running_loss:13.27879810333252\n",
      "file:50,running_loss:16.804189682006836\n",
      "file:50,running_loss:9.429277420043945\n",
      "file:50,running_loss:5.274280548095703\n",
      "file:50,running_loss:6.458006858825684\n",
      "file:50,running_loss:17.539600372314453\n",
      "file:50,running_loss:9.95724868774414\n",
      "file:50,running_loss:6.361550331115723\n",
      "file:50,running_loss:12.955915451049805\n",
      "file:50,running_loss:11.758136749267578\n",
      "file:50,running_loss:8.023734092712402\n",
      "file:50,running_loss:9.630600929260254\n",
      "file:50,running_loss:4.609375476837158\n",
      "file:50,running_loss:9.75700569152832\n",
      "file:50,running_loss:12.37447738647461\n",
      "file:50,running_loss:9.816702842712402\n",
      "file:50,running_loss:6.053152561187744\n",
      "file:50,running_loss:3.1725082397460938\n",
      "file:50,running_loss:7.326623916625977\n",
      "file:50,running_loss:8.413091659545898\n",
      "file:50,running_loss:7.8218817710876465\n",
      "file:50,running_loss:7.94213342666626\n",
      "file:50,running_loss:14.504029273986816\n",
      "file:50,running_loss:3.0740609169006348\n",
      "file:50,running_loss:9.517350196838379\n",
      "file:50,running_loss:4.365221977233887\n",
      "file:50,running_loss:4.723221778869629\n",
      "file:50,running_loss:13.84218692779541\n",
      "file:50,running_loss:24.02486228942871\n",
      "file:50,running_loss:4.135710716247559\n",
      "file:50,running_loss:9.716285705566406\n",
      "file:50,running_loss:14.928451538085938\n",
      "file:50,running_loss:5.759724140167236\n",
      "file:50,running_loss:9.743276596069336\n",
      "file:50,running_loss:6.529182434082031\n",
      "file:50,running_loss:20.31161880493164\n",
      "file:50,running_loss:4.801619529724121\n",
      "file:50,running_loss:3.747154474258423\n",
      "file:50,running_loss:10.419292449951172\n",
      "file:50,running_loss:6.796888828277588\n",
      "file:50,running_loss:7.3475341796875\n",
      "file:50,running_loss:9.169865608215332\n",
      "file:50,running_loss:5.416199684143066\n",
      "file:50,running_loss:5.564670562744141\n",
      "file:50,running_loss:6.792048454284668\n",
      "file:50,running_loss:9.48047924041748\n",
      "file:50,running_loss:6.92222261428833\n",
      "file:50,running_loss:13.400028228759766\n",
      "file:50,running_loss:15.4943265914917\n",
      "file:50,running_loss:15.241250038146973\n",
      "file:50,running_loss:14.228156089782715\n",
      "file:50,running_loss:10.609609603881836\n",
      "file:50,running_loss:12.67381477355957\n",
      "file:50,running_loss:3.573945999145508\n",
      "file:50,running_loss:6.682470321655273\n",
      "file:50,running_loss:9.29848861694336\n",
      "file:50,running_loss:8.340733528137207\n",
      "file:50,running_loss:4.277398109436035\n",
      "file:50,running_loss:11.877285957336426\n",
      "file:50,running_loss:12.06904125213623\n",
      "file:50,running_loss:8.748100280761719\n",
      "file:50,running_loss:10.061649322509766\n",
      "file:50,running_loss:19.7248592376709\n",
      "file:50,running_loss:11.18529224395752\n",
      "file:50,running_loss:9.239716529846191\n",
      "file:50,running_loss:6.807570934295654\n",
      "file:50,running_loss:7.222326278686523\n",
      "file:50,running_loss:9.169189453125\n",
      "file:50,running_loss:7.840250015258789\n",
      "file:50,running_loss:17.492958068847656\n",
      "file:50,running_loss:6.975273132324219\n",
      "file:50,running_loss:3.09049916267395\n",
      "file:50,running_loss:16.05975341796875\n",
      "file:50,running_loss:22.14592170715332\n",
      "file:50,running_loss:43.40765380859375\n",
      "file:50,running_loss:21.70123291015625\n",
      "file:50,running_loss:3.0629923343658447\n",
      "file:50,running_loss:2.302194356918335\n",
      "file:50,running_loss:2.6748909950256348\n",
      "file:50,running_loss:5.9585394859313965\n",
      "file:50,running_loss:29.501079559326172\n",
      "file:50,running_loss:9.277451515197754\n",
      "file:50,running_loss:17.34868621826172\n",
      "file:50,running_loss:18.538721084594727\n",
      "file:50,running_loss:32.03660583496094\n",
      "file:50,running_loss:52.83943176269531\n",
      "file:50,running_loss:14.903268814086914\n",
      "file:50,running_loss:12.247715950012207\n",
      "file:50,running_loss:10.85505485534668\n",
      "file:50,running_loss:29.72797393798828\n",
      "file:50,running_loss:14.190503120422363\n",
      "file:50,running_loss:7.442135810852051\n",
      "file:50,running_loss:35.13850021362305\n",
      "file:50,running_loss:42.19967269897461\n",
      "file:50,running_loss:39.43222427368164\n",
      "file:50,running_loss:56.13168716430664\n",
      "file:50,running_loss:37.015419006347656\n",
      "file:50,running_loss:43.88089370727539\n",
      "file:50,running_loss:14.964315414428711\n",
      "file:50,running_loss:12.245485305786133\n",
      "file:50,running_loss:19.967437744140625\n",
      "file:50,running_loss:15.579432487487793\n",
      "file:50,running_loss:21.07881736755371\n",
      "file:50,running_loss:2.1760101318359375\n",
      "file:50,running_loss:1.6572140455245972\n",
      "file:50,running_loss:9.12869644165039\n",
      "file:50,running_loss:12.180981636047363\n",
      "file:50,running_loss:6.947199821472168\n",
      "file:50,running_loss:6.826815605163574\n",
      "file:50,running_loss:2.922253131866455\n",
      "file:50,running_loss:5.037599086761475\n",
      "file:50,running_loss:18.34979248046875\n",
      "file:50,running_loss:18.658145904541016\n",
      "file:50,running_loss:6.525467395782471\n",
      "file:50,running_loss:2.3547205924987793\n",
      "file:50,running_loss:3.6872878074645996\n",
      "file:50,running_loss:1.4229862689971924\n",
      "file:50,running_loss:13.027599334716797\n",
      "file:50,running_loss:2.665696144104004\n",
      "file:50,running_loss:4.807773113250732\n",
      "file:50,running_loss:15.420918464660645\n",
      "file:50,running_loss:12.756697654724121\n",
      "file:50,running_loss:34.52556228637695\n",
      "file:50,running_loss:35.42018127441406\n",
      "file:50,running_loss:13.732490539550781\n",
      "file:50,running_loss:2.875213623046875\n",
      "file:50,running_loss:45.571224212646484\n",
      "file:50,running_loss:8.941771507263184\n",
      "file:50,running_loss:7.2423200607299805\n",
      "file:50,running_loss:10.41335391998291\n",
      "file:50,running_loss:67.07810974121094\n",
      "file:50,running_loss:29.613811492919922\n",
      "file:50,running_loss:13.157182693481445\n",
      "file:50,running_loss:16.126728057861328\n",
      "file:50,running_loss:23.432247161865234\n",
      "file:100,running_loss:3.8467214107513428\n",
      "file:100,running_loss:26.57021713256836\n",
      "file:100,running_loss:47.76844787597656\n",
      "file:100,running_loss:10.573705673217773\n",
      "file:100,running_loss:4.7347493171691895\n",
      "file:100,running_loss:19.21940040588379\n",
      "file:100,running_loss:79.96768951416016\n",
      "file:100,running_loss:24.536035537719727\n",
      "file:100,running_loss:14.043588638305664\n",
      "file:100,running_loss:24.575531005859375\n",
      "file:100,running_loss:32.45403289794922\n",
      "file:100,running_loss:64.73355865478516\n",
      "file:100,running_loss:43.84128189086914\n",
      "file:100,running_loss:33.658790588378906\n",
      "file:100,running_loss:38.254356384277344\n",
      "file:100,running_loss:9.854516983032227\n",
      "file:100,running_loss:55.42027282714844\n",
      "file:100,running_loss:10.168465614318848\n",
      "file:100,running_loss:24.033493041992188\n",
      "file:100,running_loss:11.267786026000977\n",
      "file:100,running_loss:24.81290626525879\n",
      "file:100,running_loss:34.12541580200195\n",
      "file:100,running_loss:9.691198348999023\n",
      "file:100,running_loss:45.546199798583984\n",
      "file:100,running_loss:4.991922378540039\n",
      "file:100,running_loss:10.887235641479492\n",
      "file:100,running_loss:45.71484375\n",
      "file:100,running_loss:43.44948196411133\n",
      "file:100,running_loss:38.474822998046875\n",
      "file:100,running_loss:21.054460525512695\n",
      "file:100,running_loss:15.705199241638184\n",
      "file:100,running_loss:25.129776000976562\n",
      "file:100,running_loss:95.51475524902344\n",
      "file:100,running_loss:30.440757751464844\n",
      "file:100,running_loss:3.7844491004943848\n",
      "file:100,running_loss:5.045507431030273\n",
      "file:100,running_loss:8.02757453918457\n",
      "file:100,running_loss:7.985029697418213\n",
      "file:100,running_loss:9.02789306640625\n",
      "file:100,running_loss:8.326130867004395\n",
      "file:100,running_loss:9.160433769226074\n",
      "file:100,running_loss:9.608057022094727\n",
      "file:100,running_loss:10.571121215820312\n",
      "file:100,running_loss:33.183860778808594\n",
      "file:100,running_loss:62.890647888183594\n",
      "file:100,running_loss:23.278339385986328\n",
      "file:100,running_loss:1.660619854927063\n",
      "file:100,running_loss:31.779512405395508\n",
      "file:100,running_loss:56.83599853515625\n",
      "file:100,running_loss:61.11533737182617\n",
      "file:100,running_loss:14.87668228149414\n",
      "file:100,running_loss:40.70515060424805\n",
      "file:100,running_loss:12.435493469238281\n",
      "file:100,running_loss:16.340450286865234\n",
      "file:100,running_loss:60.442604064941406\n",
      "file:100,running_loss:34.9808235168457\n",
      "file:100,running_loss:29.00425910949707\n",
      "file:100,running_loss:10.940922737121582\n",
      "file:100,running_loss:45.87253189086914\n",
      "file:100,running_loss:33.29587936401367\n",
      "file:100,running_loss:8.05150318145752\n",
      "file:100,running_loss:34.93193435668945\n",
      "file:100,running_loss:49.51065444946289\n",
      "file:100,running_loss:16.555509567260742\n",
      "file:100,running_loss:13.007294654846191\n",
      "file:100,running_loss:4.375704765319824\n",
      "file:100,running_loss:6.961021900177002\n",
      "file:100,running_loss:20.733535766601562\n",
      "file:100,running_loss:7.968015193939209\n",
      "file:100,running_loss:3.526416301727295\n",
      "file:100,running_loss:24.14101219177246\n",
      "file:100,running_loss:7.774942874908447\n",
      "file:100,running_loss:18.29853630065918\n",
      "file:100,running_loss:18.95241928100586\n",
      "file:100,running_loss:20.263134002685547\n",
      "file:100,running_loss:19.499832153320312\n",
      "file:100,running_loss:9.870135307312012\n",
      "file:100,running_loss:27.933334350585938\n",
      "file:100,running_loss:24.90648078918457\n",
      "file:100,running_loss:7.642321586608887\n",
      "file:100,running_loss:9.280962944030762\n",
      "file:100,running_loss:4.520176410675049\n",
      "file:100,running_loss:28.26369285583496\n",
      "file:100,running_loss:10.953482627868652\n",
      "file:100,running_loss:6.201652526855469\n",
      "file:100,running_loss:17.398725509643555\n",
      "file:100,running_loss:40.022274017333984\n",
      "file:100,running_loss:9.47730827331543\n",
      "file:100,running_loss:13.181540489196777\n",
      "file:100,running_loss:31.227867126464844\n",
      "file:100,running_loss:26.23193359375\n",
      "file:100,running_loss:21.83272361755371\n",
      "file:100,running_loss:10.110393524169922\n",
      "file:100,running_loss:30.203929901123047\n",
      "file:100,running_loss:14.956032752990723\n",
      "file:100,running_loss:16.146709442138672\n",
      "file:100,running_loss:7.491620063781738\n",
      "file:100,running_loss:17.659282684326172\n",
      "file:100,running_loss:20.93065643310547\n",
      "file:100,running_loss:8.59090805053711\n",
      "file:100,running_loss:36.79585266113281\n",
      "file:100,running_loss:10.10201358795166\n",
      "file:100,running_loss:7.250401496887207\n",
      "file:100,running_loss:11.52173900604248\n",
      "file:100,running_loss:8.16407299041748\n",
      "file:100,running_loss:9.950279235839844\n",
      "file:100,running_loss:16.5036563873291\n",
      "file:100,running_loss:6.880695819854736\n",
      "file:100,running_loss:8.36048412322998\n",
      "file:100,running_loss:3.939701557159424\n",
      "file:100,running_loss:2.668715000152588\n",
      "file:100,running_loss:3.407884359359741\n",
      "file:100,running_loss:11.054964065551758\n",
      "file:100,running_loss:19.91910171508789\n",
      "file:100,running_loss:14.885415077209473\n",
      "file:100,running_loss:16.590965270996094\n",
      "file:100,running_loss:8.310297012329102\n",
      "file:100,running_loss:7.782800674438477\n",
      "file:100,running_loss:8.552959442138672\n",
      "file:100,running_loss:10.882957458496094\n",
      "file:100,running_loss:17.13068962097168\n",
      "file:100,running_loss:13.092357635498047\n",
      "file:100,running_loss:12.511678695678711\n",
      "file:100,running_loss:20.534189224243164\n",
      "file:100,running_loss:6.318117618560791\n",
      "file:100,running_loss:6.518990516662598\n",
      "file:100,running_loss:18.37407112121582\n",
      "file:100,running_loss:14.040034294128418\n",
      "file:100,running_loss:11.83137321472168\n",
      "file:100,running_loss:28.196414947509766\n",
      "file:100,running_loss:18.16282844543457\n",
      "file:100,running_loss:8.689446449279785\n",
      "file:100,running_loss:10.425724983215332\n",
      "file:100,running_loss:5.14207649230957\n",
      "file:100,running_loss:3.875176191329956\n",
      "file:100,running_loss:4.961466312408447\n",
      "file:100,running_loss:7.262087345123291\n",
      "file:100,running_loss:5.059701442718506\n",
      "file:100,running_loss:5.277121543884277\n",
      "file:100,running_loss:4.074752330780029\n",
      "file:100,running_loss:7.408625602722168\n",
      "file:100,running_loss:4.666913986206055\n",
      "file:100,running_loss:15.741849899291992\n",
      "file:100,running_loss:7.086121559143066\n",
      "file:100,running_loss:10.356364250183105\n",
      "file:100,running_loss:10.295262336730957\n",
      "file:100,running_loss:9.039681434631348\n",
      "file:100,running_loss:19.38558006286621\n",
      "file:100,running_loss:6.255748271942139\n",
      "file:100,running_loss:3.7470624446868896\n",
      "file:100,running_loss:4.976285934448242\n",
      "file:100,running_loss:13.341621398925781\n",
      "file:100,running_loss:15.672124862670898\n",
      "file:100,running_loss:12.879866600036621\n",
      "file:100,running_loss:14.576361656188965\n",
      "file:100,running_loss:5.305435657501221\n",
      "file:100,running_loss:13.322490692138672\n",
      "file:100,running_loss:18.958677291870117\n",
      "file:100,running_loss:23.159687042236328\n",
      "file:100,running_loss:24.63067054748535\n",
      "file:100,running_loss:15.637055397033691\n",
      "file:100,running_loss:18.005325317382812\n",
      "file:100,running_loss:25.15855598449707\n",
      "file:100,running_loss:10.949711799621582\n",
      "file:100,running_loss:11.38512897491455\n",
      "file:100,running_loss:16.751262664794922\n",
      "file:100,running_loss:21.11969757080078\n",
      "file:100,running_loss:16.11919403076172\n",
      "file:100,running_loss:4.413848400115967\n",
      "file:100,running_loss:15.668055534362793\n",
      "file:100,running_loss:9.184685707092285\n",
      "file:100,running_loss:18.71913719177246\n",
      "file:100,running_loss:25.031604766845703\n",
      "file:100,running_loss:8.691441535949707\n",
      "file:100,running_loss:14.10355281829834\n",
      "file:100,running_loss:12.064666748046875\n",
      "file:100,running_loss:12.0851469039917\n",
      "file:100,running_loss:22.357379913330078\n",
      "file:100,running_loss:17.099647521972656\n",
      "file:100,running_loss:13.524218559265137\n",
      "file:100,running_loss:2.665663957595825\n",
      "file:100,running_loss:8.111692428588867\n",
      "file:100,running_loss:8.712966918945312\n",
      "file:100,running_loss:8.972585678100586\n",
      "file:100,running_loss:8.279885292053223\n",
      "file:100,running_loss:3.6933529376983643\n",
      "file:100,running_loss:7.713428020477295\n",
      "file:100,running_loss:6.846538066864014\n",
      "file:100,running_loss:18.732168197631836\n",
      "file:100,running_loss:9.587291717529297\n",
      "file:100,running_loss:12.970629692077637\n",
      "file:100,running_loss:14.192099571228027\n",
      "file:100,running_loss:11.178674697875977\n",
      "file:100,running_loss:6.203362941741943\n",
      "file:100,running_loss:11.458191871643066\n",
      "file:100,running_loss:10.827788352966309\n",
      "file:100,running_loss:11.19953441619873\n",
      "file:100,running_loss:16.078224182128906\n",
      "file:100,running_loss:17.24441146850586\n",
      "file:100,running_loss:15.90501880645752\n",
      "file:100,running_loss:19.187711715698242\n",
      "file:100,running_loss:18.870878219604492\n",
      "file:100,running_loss:16.83425521850586\n",
      "file:100,running_loss:5.656118392944336\n",
      "file:100,running_loss:5.447109222412109\n",
      "file:100,running_loss:20.143449783325195\n",
      "file:100,running_loss:13.51966667175293\n",
      "file:100,running_loss:4.285941123962402\n",
      "file:100,running_loss:22.011213302612305\n",
      "file:100,running_loss:12.687711715698242\n",
      "file:100,running_loss:24.196884155273438\n",
      "file:100,running_loss:12.275105476379395\n",
      "file:100,running_loss:9.29458236694336\n",
      "file:100,running_loss:10.132834434509277\n",
      "file:100,running_loss:7.986846446990967\n",
      "file:100,running_loss:10.648052215576172\n",
      "file:100,running_loss:7.9551568031311035\n",
      "file:100,running_loss:20.753740310668945\n",
      "file:100,running_loss:2.7925589084625244\n",
      "file:100,running_loss:8.274985313415527\n",
      "file:100,running_loss:10.103163719177246\n",
      "file:100,running_loss:9.885704040527344\n",
      "file:100,running_loss:17.35483169555664\n",
      "file:100,running_loss:15.154522895812988\n",
      "file:100,running_loss:14.018403053283691\n",
      "file:100,running_loss:15.54505443572998\n",
      "file:100,running_loss:13.6765718460083\n",
      "file:100,running_loss:24.599523544311523\n",
      "file:100,running_loss:6.978500843048096\n",
      "file:100,running_loss:8.064972877502441\n",
      "file:100,running_loss:1.6254653930664062\n",
      "file:100,running_loss:6.2451677322387695\n",
      "file:100,running_loss:15.060290336608887\n",
      "file:100,running_loss:14.526971817016602\n",
      "file:100,running_loss:9.666665077209473\n",
      "file:100,running_loss:11.894193649291992\n",
      "file:100,running_loss:9.890826225280762\n",
      "file:100,running_loss:11.36471176147461\n",
      "file:100,running_loss:0.2968858778476715\n",
      "file:100,running_loss:2.810457944869995\n",
      "file:100,running_loss:10.862100601196289\n",
      "file:100,running_loss:6.362344741821289\n",
      "file:100,running_loss:4.834066867828369\n",
      "file:100,running_loss:5.87966775894165\n",
      "file:100,running_loss:10.070905685424805\n",
      "file:100,running_loss:20.11077308654785\n",
      "file:100,running_loss:21.61597442626953\n",
      "file:100,running_loss:14.658287048339844\n",
      "file:100,running_loss:19.726781845092773\n",
      "file:100,running_loss:2.9636623859405518\n",
      "file:100,running_loss:10.807367324829102\n",
      "file:100,running_loss:19.558080673217773\n",
      "file:100,running_loss:12.216270446777344\n",
      "file:100,running_loss:3.0937788486480713\n",
      "file:100,running_loss:10.418449401855469\n",
      "file:100,running_loss:17.80509376525879\n",
      "file:100,running_loss:20.202970504760742\n",
      "file:100,running_loss:13.839749336242676\n",
      "file:100,running_loss:7.557193756103516\n",
      "file:100,running_loss:7.176612377166748\n",
      "file:100,running_loss:3.368809223175049\n",
      "file:100,running_loss:2.983961343765259\n",
      "file:100,running_loss:5.366245269775391\n",
      "file:100,running_loss:16.77707862854004\n",
      "file:100,running_loss:17.71242332458496\n",
      "file:100,running_loss:12.763676643371582\n",
      "file:100,running_loss:4.679711818695068\n",
      "file:100,running_loss:3.0393471717834473\n",
      "file:100,running_loss:14.7562837600708\n",
      "file:100,running_loss:9.53828239440918\n",
      "file:100,running_loss:8.490118980407715\n",
      "file:100,running_loss:15.751187324523926\n",
      "file:100,running_loss:7.448603630065918\n",
      "file:100,running_loss:14.016993522644043\n",
      "file:100,running_loss:5.691666126251221\n",
      "file:100,running_loss:1.4459960460662842\n",
      "file:100,running_loss:7.0552263259887695\n",
      "file:100,running_loss:9.593356132507324\n",
      "file:100,running_loss:14.707865715026855\n",
      "file:100,running_loss:15.457963943481445\n",
      "file:100,running_loss:9.609997749328613\n",
      "file:100,running_loss:5.286513805389404\n",
      "file:100,running_loss:14.22474193572998\n",
      "file:100,running_loss:10.429697036743164\n",
      "file:100,running_loss:2.420820713043213\n",
      "file:100,running_loss:16.024982452392578\n",
      "file:100,running_loss:18.05017852783203\n",
      "file:100,running_loss:8.498153686523438\n",
      "file:100,running_loss:7.122735977172852\n",
      "file:100,running_loss:6.111685752868652\n",
      "file:100,running_loss:15.227365493774414\n",
      "file:100,running_loss:8.484493255615234\n",
      "file:100,running_loss:6.9279279708862305\n",
      "file:100,running_loss:16.537431716918945\n",
      "file:100,running_loss:12.554221153259277\n",
      "file:100,running_loss:7.472301483154297\n",
      "file:100,running_loss:11.26302433013916\n",
      "file:100,running_loss:5.868491172790527\n",
      "file:100,running_loss:10.991214752197266\n",
      "file:100,running_loss:14.590291976928711\n",
      "file:100,running_loss:9.692965507507324\n",
      "file:100,running_loss:9.238203048706055\n",
      "file:100,running_loss:4.588402271270752\n",
      "file:100,running_loss:5.602626800537109\n",
      "file:100,running_loss:10.716633796691895\n",
      "file:100,running_loss:6.6631669998168945\n",
      "file:100,running_loss:9.334033966064453\n",
      "file:100,running_loss:18.071746826171875\n",
      "file:100,running_loss:9.59265422821045\n",
      "file:100,running_loss:13.91589641571045\n",
      "file:100,running_loss:6.440954685211182\n",
      "file:100,running_loss:5.298666954040527\n",
      "file:100,running_loss:12.780465126037598\n",
      "file:100,running_loss:24.114940643310547\n",
      "file:100,running_loss:3.667839765548706\n",
      "file:100,running_loss:9.08426284790039\n",
      "file:100,running_loss:13.090758323669434\n",
      "file:100,running_loss:7.4028730392456055\n",
      "file:100,running_loss:7.650328636169434\n",
      "file:100,running_loss:5.577585697174072\n",
      "file:100,running_loss:16.035322189331055\n",
      "file:100,running_loss:4.022733688354492\n",
      "file:100,running_loss:8.894646644592285\n",
      "file:100,running_loss:15.765283584594727\n",
      "file:100,running_loss:5.713431358337402\n",
      "file:100,running_loss:6.775318622589111\n",
      "file:100,running_loss:8.099334716796875\n",
      "file:100,running_loss:5.016429424285889\n",
      "file:100,running_loss:4.390102386474609\n",
      "file:100,running_loss:8.77149486541748\n",
      "file:100,running_loss:18.925378799438477\n",
      "file:100,running_loss:10.251049995422363\n",
      "file:100,running_loss:12.192598342895508\n",
      "file:100,running_loss:17.648696899414062\n",
      "file:100,running_loss:14.241096496582031\n",
      "file:100,running_loss:15.065927505493164\n",
      "file:100,running_loss:18.201053619384766\n",
      "file:100,running_loss:9.957636833190918\n",
      "file:100,running_loss:4.417082786560059\n",
      "file:100,running_loss:6.1142897605896\n",
      "file:100,running_loss:10.451776504516602\n",
      "file:100,running_loss:9.684890747070312\n",
      "file:100,running_loss:9.449264526367188\n",
      "file:100,running_loss:13.0642671585083\n",
      "file:100,running_loss:10.423608779907227\n",
      "file:100,running_loss:6.229174613952637\n",
      "file:100,running_loss:13.096588134765625\n",
      "file:100,running_loss:18.973751068115234\n",
      "file:100,running_loss:14.107412338256836\n",
      "file:100,running_loss:13.524069786071777\n",
      "file:100,running_loss:9.156720161437988\n",
      "file:100,running_loss:2.2985336780548096\n",
      "file:100,running_loss:12.471613883972168\n",
      "file:100,running_loss:5.839520454406738\n",
      "file:100,running_loss:32.57744216918945\n",
      "file:100,running_loss:6.733085632324219\n",
      "file:100,running_loss:11.186074256896973\n",
      "file:100,running_loss:12.295154571533203\n",
      "file:100,running_loss:20.67751121520996\n",
      "file:100,running_loss:43.271400451660156\n",
      "file:100,running_loss:16.418346405029297\n",
      "file:100,running_loss:2.3055825233459473\n",
      "file:100,running_loss:0.7970951199531555\n",
      "file:100,running_loss:1.4529894590377808\n",
      "file:100,running_loss:10.312037467956543\n",
      "file:100,running_loss:38.47178649902344\n",
      "file:100,running_loss:7.036474227905273\n",
      "file:100,running_loss:18.01207733154297\n",
      "file:100,running_loss:15.789490699768066\n",
      "file:100,running_loss:34.83451843261719\n",
      "file:100,running_loss:54.031368255615234\n",
      "file:100,running_loss:14.850082397460938\n",
      "file:100,running_loss:16.575927734375\n",
      "file:100,running_loss:11.832197189331055\n",
      "file:100,running_loss:53.894012451171875\n",
      "file:100,running_loss:12.258150100708008\n",
      "file:100,running_loss:5.972901344299316\n",
      "file:100,running_loss:35.29964828491211\n",
      "file:100,running_loss:39.89004135131836\n",
      "file:100,running_loss:35.655269622802734\n",
      "file:100,running_loss:44.72856140136719\n",
      "file:100,running_loss:45.35601806640625\n",
      "file:100,running_loss:49.89313888549805\n",
      "file:100,running_loss:12.420604705810547\n",
      "file:100,running_loss:14.588496208190918\n",
      "file:100,running_loss:20.237808227539062\n",
      "file:100,running_loss:11.089553833007812\n",
      "file:100,running_loss:31.24009895324707\n",
      "file:100,running_loss:6.904298305511475\n",
      "file:100,running_loss:2.4913763999938965\n",
      "file:100,running_loss:14.964479446411133\n",
      "file:100,running_loss:12.438838958740234\n",
      "file:100,running_loss:8.354203224182129\n",
      "file:100,running_loss:5.420891761779785\n",
      "file:100,running_loss:3.49261474609375\n",
      "file:100,running_loss:6.56240701675415\n",
      "file:100,running_loss:18.760387420654297\n",
      "file:100,running_loss:15.639460563659668\n",
      "file:100,running_loss:11.817479133605957\n",
      "file:100,running_loss:5.977581024169922\n",
      "file:100,running_loss:2.622317314147949\n",
      "file:100,running_loss:1.9215562343597412\n",
      "file:100,running_loss:8.297505378723145\n",
      "file:100,running_loss:6.160671710968018\n",
      "file:100,running_loss:3.5070862770080566\n",
      "file:100,running_loss:11.376571655273438\n",
      "file:100,running_loss:19.0279541015625\n",
      "file:100,running_loss:39.68550109863281\n",
      "file:100,running_loss:41.02742004394531\n",
      "file:100,running_loss:9.479893684387207\n",
      "file:100,running_loss:1.2977322340011597\n",
      "file:100,running_loss:59.70698547363281\n",
      "file:100,running_loss:12.855841636657715\n",
      "file:100,running_loss:2.6105616092681885\n",
      "file:100,running_loss:10.50413703918457\n",
      "file:100,running_loss:76.48832702636719\n",
      "file:100,running_loss:39.88192367553711\n",
      "file:100,running_loss:8.49206256866455\n",
      "file:100,running_loss:8.166936874389648\n",
      "file:100,running_loss:22.78478240966797\n",
      "###epoch:1,train_loss:22.78478240966797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m WindDataSet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,num_steps)\n\u001b[1;32m      6\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset,batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m###epoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,train_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m save_net(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMM2-epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,net\u001b[38;5;241m=\u001b[39mnet\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, net, train_loader, device, train_loss)\u001b[0m\n\u001b[1;32m     13\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat,y)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     14\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgrad_clipping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m runing_loss \u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mgrad_clipping\u001b[0;34m(net, theta)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m>\u001b[39m theta:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m----> 9\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad[:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtheta\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnorm\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:38\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(path='MM_epoch0.pt',net=None):\n",
    "    net.load_state_dict(torch.load(path))\n",
    "load_net(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix,net,device):\n",
    "    state = net.begin_state(batch_size=1,device=device)\n",
    "    outputs = [prefix[0]]\n",
    "    get_input = lambda:torch.tensor([outputs[-1]],device=device).reshape(1,1,INPUT_SIZE)\n",
    "    for y in prefix[1:]:\n",
    "        _,state = net(get_input(),state)\n",
    "        outputs.append(y)\n",
    "    y_hat,_ = net(get_input(),state)\n",
    "    return y_hat#torch.cat(outputs,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WindDataSet('.datasets/141.csv',num_steps=100)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "preds,truthes=[],[]\n",
    "for batch_idx,(X, y) in enumerate(test_loader):\n",
    "    if batch_idx % 10 == 0:\n",
    "        X = (X.reshape(1,1,INPUT_SIZE).to(torch.float32))\n",
    "        pred = np.array(predict(X,net.to(device),device).reshape(-1).to('cpu').detach())\n",
    "        truth=y.reshape(-1).detach().numpy()\n",
    "        preds= np.append(preds,pred)\n",
    "        truthes= np.append(truthes,truth)\n",
    "    if batch_idx > 100:\n",
    "        break\n",
    "    \n",
    "print(preds)\n",
    "print(truthes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(truth, label='True Values', color='blue')\n",
    "plt.plot(preds[100:], label='Predictions', color='red')\n",
    "plt.title('',fontproperties=my_font)\n",
    "plt.xlabel('',fontproperties=my_font)\n",
    "plt.ylabel('',fontproperties=my_font)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
